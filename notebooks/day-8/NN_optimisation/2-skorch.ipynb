{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2-skorch.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"name":"python","nbconvert_exporter":"python","mimetype":"text/x-python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","version":"3.5.2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gHvlahm8sdHn","colab_type":"text"},"source":["# Skorch introduction\n","\n","(borrowed from [skorch](https://skorch.readthedocs.io) documentation)"]},{"cell_type":"markdown","metadata":{"id":"8C_Zi4PosdHp","colab_type":"text"},"source":["*`skorch`* is designed to maximize interoperability between `sklearn` and `pytorch`. The aim is to keep 99% of the flexibility of `pytorch` while being able to leverage most features of `sklearn`. Below, we show the basic usage of `skorch` and how it can be combined with `sklearn`.\n"]},{"cell_type":"code","metadata":{"id":"iYcmHUz2sdHw","colab_type":"code","colab":{}},"source":["! [ ! -z \"$COLAB_GPU\" ] && pip install skorch scikit-learn==0.20.3"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LrER0JNHsdH7","colab_type":"code","colab":{}},"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","\n","torch.manual_seed(0);"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fp45SEoesdIA","colab_type":"text"},"source":["\n","## Training a classifier and making predictions"]},{"cell_type":"markdown","metadata":{"id":"IdH4bpDAsdID","colab_type":"text"},"source":["### A toy binary classification task"]},{"cell_type":"markdown","metadata":{"id":"_ZIe445asdIF","colab_type":"text"},"source":["We load a toy classification task from `sklearn`."]},{"cell_type":"code","metadata":{"id":"_RyajDFzsdIH","colab_type":"code","colab":{}},"source":["import numpy as np\n","from sklearn.datasets import make_classification"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jlvFVXbEsdIN","colab_type":"code","colab":{}},"source":["X, y = make_classification(1000, 20, n_informative=10, n_classes=2, random_state=0)\n","X = X.astype(np.float32)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"3UN4yjlysdIa","colab_type":"code","colab":{}},"source":["X.shape, y.shape, y.mean()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CC2yNBMTsdIm","colab_type":"text"},"source":["### Definition of the `pytorch` classification `module`"]},{"cell_type":"markdown","metadata":{"id":"7oe_jOBXsdIn","colab_type":"text"},"source":["We define a vanilla neural network with two hidden layers. The output layer should have 2 output units since there are two classes. In addition, it should have a softmax nonlinearity, because later, when calling `predict_proba`, the output from the `forward` call will be used."]},{"cell_type":"code","metadata":{"id":"u0V9nuedsdIo","colab_type":"code","colab":{}},"source":["class ClassifierModule(nn.Module):\n","    def __init__(\n","            self,\n","            num_units=10,\n","            nonlin=F.relu,\n","            dropout=0.5,\n","    ):\n","        super(ClassifierModule, self).__init__()\n","\n","        self.dense0 = nn.Linear(20, num_units)\n","        self.nonlin = nonlin\n","        self.dropout = nn.Dropout(dropout)\n","        self.dense1 = nn.Linear(num_units, 10)\n","        self.output = nn.Linear(10, 2)\n","\n","    def forward(self, X, **kwargs):\n","        X = self.nonlin(self.dense0(X))\n","        X = self.dropout(X)\n","        X = F.relu(self.dense1(X))\n","        X = F.softmax(self.output(X), dim=-1)\n","        return X"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pj-n5AgUsdIs","colab_type":"text"},"source":["### Defining and training the neural net classifier"]},{"cell_type":"markdown","metadata":{"id":"hJ7PzCqosdIv","colab_type":"text"},"source":["We use `NeuralNetClassifier` because we're dealing with a classifcation task. The first argument should be the `pytorch module`. As additional arguments, we pass the number of epochs and the learning rate (`lr`), but those are optional.\n","\n","*Note*: To use the CUDA backend, pass `device='cuda'` as an additional argument."]},{"cell_type":"code","metadata":{"id":"s9MsKiTPsdIw","colab_type":"code","colab":{}},"source":["from skorch import NeuralNetClassifier"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MPqytGnpsdI-","colab_type":"code","colab":{}},"source":["net = NeuralNetClassifier(\n","    ClassifierModule,\n","    max_epochs=20,\n","    lr=0.1,\n","    device='cuda',  # comment this to train with CPU\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UrJKaypCsdJK","colab_type":"text"},"source":["As in `sklearn`, we call `fit` passing the input data `X` and the targets `y`. By default, `NeuralNetClassifier` makes a `StratifiedKFold` split on the data (80/20) to track the validation loss. This is shown, as well as the train loss and the accuracy on the validation set."]},{"cell_type":"code","metadata":{"scrolled":false,"id":"LVYsuRmlsdJR","colab_type":"code","colab":{}},"source":["net.fit(X, y)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A4Iboct1sdJa","colab_type":"text"},"source":["Also, as in `sklearn`, you may call `predict` or `predict_proba` on the fitted model."]},{"cell_type":"markdown","metadata":{"id":"eWVppbCEsdJb","colab_type":"text"},"source":["### Making predictions, classification"]},{"cell_type":"code","metadata":{"id":"B2mAMsh6sdJc","colab_type":"code","colab":{}},"source":["y_pred = net.predict(X[:5])\n","y_pred"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NtRHJIiQsdJf","colab_type":"code","colab":{}},"source":["y_proba = net.predict_proba(X[:5])\n","y_proba"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zDxsb514sdJj","colab_type":"text"},"source":["## Usage with sklearn `GridSearchCV`"]},{"cell_type":"markdown","metadata":{"id":"3Ygtq1a5sdJj","colab_type":"text"},"source":["### Special prefixes"]},{"cell_type":"markdown","metadata":{"id":"MlLAYtb4sdJk","colab_type":"text"},"source":["The `NeuralNet` class allows to directly access parameters of the `pytorch module` by using the `module__` prefix. So e.g. if you defined the `module` to have a `num_units` parameter, you can set it via the `module__num_units` argument. This is exactly the same logic that allows to access estimator parameters in `sklearn Pipeline`s and `FeatureUnion`s."]},{"cell_type":"markdown","metadata":{"id":"0ezV8EqGsdJm","colab_type":"text"},"source":["This feature is useful in several ways. For one, it allows to set those parameters in the model definition. Furthermore, it allows you to set parameters in an `sklearn GridSearchCV` as shown below."]},{"cell_type":"markdown","metadata":{"id":"TE1UKqnRsdJn","colab_type":"text"},"source":["In addition to the parameters prefixed by `module__`, you may access a couple of other attributes, such as those of the optimizer by using the `optimizer__` prefix (again, see below). All those special prefixes are stored in the `prefixes_` attribute:"]},{"cell_type":"code","metadata":{"id":"rAZ6pbwJsdJo","colab_type":"code","colab":{}},"source":["print(', '.join(net.prefixes_))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Iv2vi2wjsdJy","colab_type":"text"},"source":["### Performing a grid search"]},{"cell_type":"markdown","metadata":{"id":"S68rq4W5sdJy","colab_type":"text"},"source":["Below we show how to perform a grid search over the learning rate (`lr`), the module's number of hidden units (`module__num_units`), the module's dropout rate (`module__dropout`), and whether the SGD optimizer should use Nesterov momentum or not (`optimizer__nesterov`)."]},{"cell_type":"code","metadata":{"id":"OaLce-aasdJz","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import GridSearchCV"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U3-mOrJgsdJ1","colab_type":"code","colab":{}},"source":["net = NeuralNetClassifier(\n","    ClassifierModule,\n","    max_epochs=20,\n","    lr=0.1,\n","    verbose=0,\n","    optimizer__momentum=0.9,\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ZMTv4YOsdJ5","colab_type":"code","colab":{}},"source":["params = {\n","    'lr': [0.05, 0.1],\n","    'module__num_units': <YOUR CODE>, # range from 10 to 50\n","    'module__dropout': <YOUR CODE>, # range from 0.1 to 0.3\n","    'optimizer__nesterov': [False, True],\n","}\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWsXCeSLsdJ-","colab_type":"code","colab":{}},"source":["gs = GridSearchCV(net, params, refit=False, cv=3, scoring='accuracy', \n","                  verbose=1, n_jobs=2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xJVYZwzZsdKF","colab_type":"code","colab":{}},"source":["gs.fit(X, y);"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bnUo1MB-ujou","colab_type":"code","colab":{}},"source":["# Utility function to report best scores\n","def report(results, n_top=3):\n","    for i in range(1, n_top + 1):\n","        candidates = np.flatnonzero(results['rank_test_score'] == i)\n","        for candidate in candidates:\n","            print(\"Model with rank: {0}\".format(i))\n","            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n","                  results['mean_test_score'][candidate],\n","                  results['std_test_score'][candidate]))\n","            print(\"Parameters: {0}\".format(results['params'][candidate]))\n","            print(\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dEzEOrqhuklH","colab_type":"code","colab":{}},"source":["report(gs.cv_results_)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X9TnlAsdunVL","colab_type":"text"},"source":["Other skorch capabilities:\n","\n","- [Saving and loading models](https://skorch.readthedocs.io/en/stable/user/save_load.html)\n","- [Accessing history of network training](https://skorch.readthedocs.io/en/stable/user/history.html)\n","- [Enhance training by callbacks](https://skorch.readthedocs.io/en/stable/user/callbacks.html)\n","\n","also link to examples: https://skorch.readthedocs.io/en/stable/user/tutorials.html"]},{"cell_type":"code","metadata":{"id":"EfHX0FqvHiWa","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}